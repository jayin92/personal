+++
title = "Jie-Ying Lee 李杰穎"
+++

{{< figure class="avatar" src="/avatar.jpg" alt="avatar">}}

Undergraduate Student  
Department of Computer Science  
National Yang Ming Chiao Tung University, Taiwan

Exchange Student  
Department of Computer Science  
ETH Zürich, Switzerland

Email: [jayinnn.cs10@nycu.edu.tw](mailto:jayinnn.cs10@nycu.edu.tw), [jielee@ethz.ch](mailto:jielee@ethz.ch)

[Personal Page](https://jayinnn.dev) | [GitHub](http://github.com/jayin92) | [LinkedIn](https://www.linkedin.com/in/jayinnn/) | [Google Scholar](https://scholar.google.com/citations?view_op=list_works&hl=zh-TW&user=mKB6voEAAAAJ) | [Personal Blog](https://blog.jayinnn.dev/) | [CV](https://raw.githubusercontent.com/jayin92/CV/main/cv.pdf)



## About Me

Hi! I'm Jie-Ying Lee, a Computer Science undergraduate at National Yang Ming Chiao Tung University and current exchange student at ETH Zurich. I serve as a research assistant at the Comp Photo Lab under [Prof. Yu-Lun Liu](https://yulunalexliu.github.io/).

In Summer 2024, I interned at Google's Pixel Camera Team, working on integrating the Segment Anything Model (SAM) for mobile devices under the guidance of [Yu-Lin Chang](https://scholar.google.com/citations?user=0O9rukQAAAAJ&hl=en) and Chung-Kai Hsieh. My previous industry experience includes roles as an R&D Intern at Microsoft and a Backend Engineer Intern at Appier.

**I'm planning to pursue a Ph.D. in 2026 and am eager to explore research collaborations.**

Beyond academics, I'm passionate about badminton, dance, and [photography](https://www.instagram.com/photograbear_/).

## Research Interest

- 3D Reconstruction
  - NeRFs
  - 3D Gaussian splatting
  - Large-scale scenes
  - Satellite imagery
- 3D Generation
  - Large-scale scenes
  - Object

## News

- Mar. 2025: Two papers accepted to CVPR 2025: "AuraFusion360" and "SpectroMotion"!
- Sep. 2024: Began exchange studies in the Department of Computer Science (D-INFK) at ETH Zurich
- Aug. 2024: Co-authored "BoostMVSNeRFs" paper accepted to the ECCV 2024 Wild3D Workshop as a poster presentation
- Jul. 2024: My work, BEVGaussian, won the [陽明交大資工系專題競賽佳作 (3rd place of the NYCU CS Undergraduate Research Competition)](https://www.cs.nycu.edu.tw/storage/materials/xeXTWKdsG4IkteKZGx3lxO6WdeZv4Qi0mgaomFJr.pdf)!
- Jun. 2024: My work, Unbounded Scene Generation, are awarded the [國科會大專學生研究計畫 (NSTC Research Grant for University Students)](https://www.nstc.gov.tw/folksonomy/list/2af9ad9a-1f47-450d-b5a1-2cb43de8290c?l=ch)!
- May 2024: Co-authored "BoostMVSNeRFs" paper accepted to SIGGRAPH 2024!  

## Publications

{{< publication-with-teaser image="/images/publications/spectromotion-teaser.jpg" video="/videos/publications/spectromotion-teaser.mp4" title="SpectroMotion" >}}
[**SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes**](https://cdfan0627.github.io/spectromotion/)  
Cheng-De Fan, Chen-Wei Chang, Yi-Ruei Liu, **Jie-Ying Lee**, Jiun-Long Huang, Yu-Chee Tseng, Yu-Lun Liu  
*IEEE/CVF Conference on Computer Vision and Pattern Recognition **(CVPR)**, 2025.*
{{< /publication-with-teaser >}}

{{< publication-with-teaser image="/images/publications/aurafusion360-teaser.jpg" video="/videos/publications/aurafusion360-teaser.mp4" title="AuraFusion360" >}}
[**AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360° Unbounded Scene Inpainting**](https://kkennethwu.github.io/aurafusion360/)  
Chung-Ho Wu, Yang-Jung Chen, Ying-Huan Chen, **Jie-Ying Lee**, Bo-Hsu Ke, Chun-Wei Tuan Mu, Yi-Chuan Huang, Chin-Yang Lin, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu  
*IEEE/CVF Conference on Computer Vision and Pattern Recognition **(CVPR)**, 2025.*
{{< /publication-with-teaser >}}

{{< publication-with-teaser image="/images/publications/boostmvsnerfs-teaser.jpg" video="/videos/publications/boostmvsnerfs-teaser.mp4" title="BoostMVSNeRFs" >}}
[**BoostMVSNeRFs: Boosting MVS-based NeRFs to Generalizable View Synthesis in Large-scale Scenes**](https://su-terry.github.io/BoostMVSNeRFs/)  
Chih-Hai Su*, Chih-Yao Hu*, Shr-Ruei Tsai*, **Jie-Ying Lee***, Chin-Yang Lin, Yu-Lun Liu (*Equal Contribution)  
*ACM Special Interest Group on Computer Graphics and Interactive Techniques **(SIGGRAPH)**, 2024.*
{{< /publication-with-teaser >}}
