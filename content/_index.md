+++
title = "Jie-Ying Lee 李杰穎"
+++

{{< figure class="avatar" src="/avatar.jpg" alt="avatar">}}

Undergraduate Student  
Department of Computer Science  
National Yang Ming Chiao Tung University, Taiwan

Exchange Student  
Department of Computer Science  
ETH Zürich, Switzerland

Email: [jayinnn.cs10@nycu.edu.tw](mailto:jayinnn.cs10@nycu.edu.tw), [jielee@ethz.ch](mailto:jielee@ethz.ch)

[Personal Page](https://jayinnn.dev) | [GitHub](http://github.com/jayin92) | [LinkedIn](https://www.linkedin.com/in/jayinnn/) | [Google Scholar](https://scholar.google.com/citations?view_op=list_works&hl=zh-TW&user=mKB6voEAAAAJ) | [Personal Blog](https://blog.jayinnn.dev/) | [CV](https://raw.githubusercontent.com/jayin92/CV/main/cv.pdf)



## About Me

Hi! I'm Jie-Ying Lee, a Computer Science undergraduate at National Yang Ming Chiao Tung University and current exchange student at ETH Zurich. I serve as a research assistant at the Comp Photo Lab under [Prof. Yu-Lun Liu](https://yulunalexliu.github.io/).

In Summer 2024, I interned at Google's Pixel Camera Team, working on integrating the Segment Anything Model (SAM) for mobile devices under the guidance of [Yu-Lin Chang](https://scholar.google.com/citations?user=0O9rukQAAAAJ&hl=en) and Chung-Kai Hsieh. My previous industry experience includes roles as an R&D Intern at Microsoft and a Backend Engineer Intern at Appier.

**I'm planning to pursue a Ph.D. in 2026 and am eager to explore research collaborations.**

Beyond academics, I'm passionate about badminton, dance, and [photography](https://www.instagram.com/photograbear_/).

## Research Interest

- 3D Reconstruction
    - NeRFs
    - 3D Gaussian Splatting
    - Large-scale scenes
    - Satellite Imagery
- 3D Generation
  - Unbounded Scene
  - Object

## News

- Sep. 2024: Began exchange studies in the Department of Computer Science (D-INFK) at ETH Zurich
- Aug. 2024: Co-authored "BoostMVSNeRFs" paper accepted to the ECCV 2024 Wild3D Workshop as a poster presentation
- Jul. 2024: My work, BEVGaussian, won the [陽明交大資工系專題競賽佳作 (3rd place of the NYCU CS Undergraduate Research Competition)](https://www.cs.nycu.edu.tw/storage/materials/xeXTWKdsG4IkteKZGx3lxO6WdeZv4Qi0mgaomFJr.pdf)!
- Jun. 2024: My work, Unbounded Scene Generation, are awarded the [國科會大專學生研究計畫 (NSTC Research Grant for University Students)](https://www.nstc.gov.tw/folksonomy/list/2af9ad9a-1f47-450d-b5a1-2cb43de8290c?l=ch)!
- May 2024: Co-authored "BoostMVSNeRFs" paper accepted to SIGGRAPH 2024!  

## Publications

[**BoostMVSNeRFs: Boosting MVS-based NeRFs to Generalizable View Synthesis in Large-scale Scenes**](https://su-terry.github.io/BoostMVSNeRFs/)  
Chih-Hai Su*, Chih-Yao Hu*, Shr-Ruei Tsai*, **Jie-Ying Lee***, Chin-Yang Lin, Yu-Lun Liu (*Equal Contribution)  
*ACM Special Interest Group on Computer Graphics and Interactive Techniques **(SIGGRAPH)**, 2024.*
